{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multiple Scopus Author IDs to retrieve lists of articles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from pandas.io.json import json_normalize  \n",
    "import nltk\n",
    "import re\n",
    "import io\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import panel as pn\n",
    "import panel.widgets \n",
    "from pathlib import Path\n",
    "from panel.interact import interact\n",
    "import hvplot.pandas\n",
    "import param\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import time\n",
    "import datetime as dt\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No File\n",
      "Launching server at http://localhost:51943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x263ebd8ce88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No File\n"
     ]
    }
   ],
   "source": [
    "# Search request function \n",
    "\n",
    "class search_scopus_dash(param.Parameterized):\n",
    "    \n",
    "    Query  = param.String(default=\"Nanosafety\", doc=\"Insert query term(s)\")\n",
    "    \n",
    "    Year_Range = param.Range((2005, 2010), bounds=(1970, 2021))\n",
    "    \n",
    "    @param.depends(\"Query\", \"Year_Range\")\n",
    "    def search_request_funt(self):\n",
    "    \n",
    "        scopus_search_appended_df = pd.DataFrame()\n",
    "    \n",
    "        if self.Year_Range[0] == self.Year_Range[1]:\n",
    "            date = str(self.Year_Range[0])\n",
    "        else: \n",
    "            date = str(self.Year_Range[0]) + \"-\" + str(self.Year_Range[1])\n",
    "        # Declare necessary parameters for Scopus request API search tool\n",
    "        cursor = \"*\"\n",
    "        field = \"prism:coverDate,dc:title,dc:description\"\n",
    "        url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "        headers = {\"X-ELS-APIKey\": api_key, 'Accept':'application/json'}\n",
    "        parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "        article_response = requests.get(url, headers=headers, params=parameters)\n",
    "        article_response_json = article_response.json()\n",
    "        total_results = int(article_response_json['search-results']['opensearch:totalResults'])\n",
    "        while article_response_json['search-results'].get('entry') is not None:\n",
    "            url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "            parameters = {\"query\": self.Query, \"view\": \"Complete\", \"date\": date, \"field\": field, \"cursor\": cursor}\n",
    "            article_response = requests.get(url, headers=headers, params= parameters)\n",
    "            article_response_json = article_response.json()\n",
    "            if article_response_json['search-results'].get('entry') is not None:\n",
    "                scopus_articles_df = pd.DataFrame.from_dict(pd.json_normalize(article_response_json, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"]), orient=\"columns\")\n",
    "                date_title_description_df = scopus_articles_df[[\"prism:coverDate\", \"dc:title\", \"dc:description\"]]\n",
    "                date_title_description_df.columns = ['Date','Title','Content']\n",
    "                pd.to_datetime(date_title_description_df['Date'], format = \"%Y-%m-%d\")\n",
    "                date_title_description_df.sort_values(by='Date')\n",
    "                date_title_description_df = date_title_description_df.set_index('Date')\n",
    "                scopus_search_appended_df = scopus_search_appended_df.append(date_title_description_df)\n",
    "                cursor = article_response_json['search-results']['cursor']['@next']\n",
    "        return scopus_search_appended_df\n",
    "\n",
    "\n",
    "\n",
    "    def make_csv(self):\n",
    "        csv = self.search_request_funt().to_csv(\"Scopus_Search_\" + \"_\" + self.Query + \"_\" + str(self.Year_Range[0]) + \"_\" + str(self.Year_Range[1]) + \".csv\")\n",
    "        return csv\n",
    "    \n",
    "    \n",
    "    def make_panel_df(self):\n",
    "        df_panel = pn.widgets.DataFrame(self.search_request_funt(), name = 'Scopus_Request_Dataframe', fit_columns = True,\n",
    "                                        height_policy = 'fixed', width_policy = 'fixed', width = 1200, height = 600)\n",
    "        return df_panel\n",
    "    \n",
    "    def freq_plot_funt(self):\n",
    "        scopus_search_appended_df = self.search_request_funt()\n",
    "        scopus_search_appended_df = scopus_search_appended_df.reset_index()\n",
    "        scopus_search_appended_df['Date'] = pd.to_datetime(scopus_search_appended_df['Date'], format = \"%Y-%m-%d\")\n",
    "        scopus_search_appended_year = scopus_search_appended_df.Date.dt.year.unique()\n",
    "        scopus_search_appended_count = scopus_search_appended_df['Date'].groupby(scopus_search_appended_df.Date.dt.year).agg('count')\n",
    "        scopus_search_appended_count_df = pd.DataFrame(scopus_search_appended_count)\n",
    "        scopus_search_appended_count_df.columns = ['Count']\n",
    "        scopus_search_appended_count_df = scopus_search_appended_count_df.reset_index() \n",
    "        plot = scopus_search_appended_count_df.hvplot.line(title= \"Total Count per Year for the Word '\" + self.Query + \"' used in Academic Articles\", \n",
    "                                    x = \"Date\", \n",
    "                                    y = 'Count',\n",
    "                                    invert = False, \n",
    "                                    height = 600,\n",
    "                                    width = 800\n",
    "                                    )\n",
    "        return plot\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def csv_path(self):\n",
    "        scopus_search_path = Path(\"Scopus_Search_\" + \"_\" + search_scopus_dash.Query + \"_\" + str(search_scopus_dash.Year_Range[0]) + \"_\" + str(search_scopus_dash.Year_Range[1]) + \".csv\", header = 0)\n",
    "        scopus = pd.read_csv(scopus_search_path)\n",
    "        return scopus\n",
    "\n",
    "class word_dash(param.Parameterized):\n",
    "    \n",
    "    # Y value multiselectors\n",
    "    Column_Selector = param.ObjectSelector(default = 'Title', objects=['Title', 'Content'])\n",
    "\n",
    "    # Word Count Slider\n",
    "    Word_Slider = param.Integer(15, bounds=(5,50))\n",
    "\n",
    "    # Stop word addition\n",
    "    Text_Input = param.String(default='', doc= 'Type Words Here, Seperated by a Space')\n",
    "    \n",
    "    File_Input = param.Parameter()\n",
    "    \n",
    "    data = param.DataFrame()\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.param.File_Input.default = pn.widgets.FileInput()\n",
    "        super().__init__(**params)\n",
    "        widgets = {\n",
    "            \"Column_Selector\": {\n",
    "                \"type\": pn.widgets.Select\n",
    "            },\n",
    "            \"Word_Slider\": {\n",
    "                \"type\": pn.widgets.IntSlider(name = 'Total Words', start=0, end= 50, step = 1, value = 10, value_throttled= 10),\n",
    "                \"throttled\": True,\n",
    "            },\n",
    "            \"Text_Input\": {\n",
    "                \"type\": pn.widgets.TextInput(name='', placeholder= 'Type Words Here, Seperated by a Space')\n",
    "            },\n",
    "        }\n",
    "        self.controls = pn.Param(self, widgets=widgets)\n",
    "        \n",
    "    \n",
    "    @pn.depends(\"File_Input.value\", watch=True)\n",
    "    def _parse_file_input(self):\n",
    "        value = self.File_Input.value\n",
    "        data_df = pd.DataFrame()\n",
    "        if value:\n",
    "            #string_io = io.StringIO(value.decode(\"utf8\"))\n",
    "            data_df = pd.read_csv(value)\n",
    "            return data_df\n",
    "        else:\n",
    "            print(\"No File\")\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    @param.depends(\"controls\")\n",
    "    def dataframe_to_string(self):\n",
    "        if self._parse_file_input() != 0:\n",
    "            scopus = self._parse_file_input()\n",
    "            if self.Column_Selector == 'Content':\n",
    "                for row in scopus:\n",
    "                    big_string = ''.join(str(scopus['Content']))\n",
    "                sw = set(stopwords.words('english'))\n",
    "                regex = re.compile(\"[^a-zA-Z ]\")\n",
    "                wordlist = re.sub(\"[^\\w]\", \" \",  self.Text_Input).split()\n",
    "                sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "                sw_addons.update(wordlist)\n",
    "                re_clean = regex.sub('', big_string)\n",
    "                words = word_tokenize(re_clean)\n",
    "                lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "                output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "                full_string = ' '.join(output)\n",
    "                wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= self.Word_Slider).generate(full_string)\n",
    "                image_1 = wc_content.to_image()\n",
    "                return image_1\n",
    "            else:\n",
    "                for row in scopus:\n",
    "                    big_string = ''.join(str(scopus['Title']))\n",
    "                sw = set(stopwords.words('english'))\n",
    "                regex = re.compile(\"[^a-zA-Z ]\")\n",
    "                wordlist = re.sub(\"[^\\w]\", \" \",  self.Text_Input).split()\n",
    "                sw_addons = {'using', 'via', 'based', 'nan', 'date', 'used', 'b', 'tio', 'nanote'}\n",
    "                sw_addons.update(wordlist)\n",
    "                re_clean = regex.sub('', big_string)\n",
    "                words = word_tokenize(re_clean)\n",
    "                lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "                output = [word.lower() for word in lem if word.lower() not in sw.union(sw_addons)]\n",
    "                full_string = ' '.join(output)\n",
    "                wc_content = WordCloud(width=800, height=600, background_color=\"white\", max_words= self.Word_Slider).generate(full_string)\n",
    "                image_2 = wc_content.to_image()\n",
    "                return image_2\n",
    "    \n",
    "    \n",
    "search = search_scopus_dash(name='Query Search Request Below')\n",
    "word = word_dash()\n",
    "                              \n",
    "fd = pn.widgets.FileDownload(callback=search.make_csv, filename=\"Scopus Search Excel File\")\n",
    "\n",
    "search_dash_tab = pn.Column('# Download Dataframe and Excel Files Here',\n",
    "                            '### This can take take between a few minutes to several minutes depending on the data size requested',\n",
    "                            pn.Row(pn.Column(search.param, fd), search.make_panel_df), background='#f0f0f0')\n",
    "\n",
    "freq_plot_tab = pn.Column('# Frequency Plot', pn.Row(search.freq_plot_funt), background='#f0f0f0')\n",
    "\n",
    "word_cloud_tab = pn.Column('# Word Cloud', pn.Column(word.controls, word.dataframe_to_string), background='#f0f0f0')\n",
    "\n",
    "all_tabs = pn.Tabs(('Data Selection', search_dash_tab), ('Frequency Plot', freq_plot_tab), ('Word Cloud', word_cloud_tab))\n",
    "all_tabs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-15</th>\n",
       "      <td>Pulmonary responses to printer toner particles...</td>\n",
       "      <td>The release of ultrafine particles from office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-14</th>\n",
       "      <td>Strategy for the modification of electrospun f...</td>\n",
       "      <td>A method to functionalize surfaces of electros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-10</th>\n",
       "      <td>Management of nanomaterials safety in research...</td>\n",
       "      <td>Despite numerous discussions, workshops, revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-07</th>\n",
       "      <td>In vitro model on glass surfaces for complex i...</td>\n",
       "      <td>This report establishes an in vitro model on g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-01</th>\n",
       "      <td>The evolving nanotechnology environmental, hea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-01</th>\n",
       "      <td>Translocation of inhaled TiO&lt;inf&gt;2&lt;/inf&gt; nanop...</td>\n",
       "      <td>Nanosized TiO2 is widely used for cleaning air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-01</th>\n",
       "      <td>Status of study on biological and toxicologica...</td>\n",
       "      <td>Because the physical and chemical properties o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-01</th>\n",
       "      <td>The promise and threat of nanotechnology: Can ...</td>\n",
       "      <td>The growing presence of the products of nanote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-01</th>\n",
       "      <td>Environmentally responsible development of nan...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-01</th>\n",
       "      <td>Societal implications of nanoscience and nanot...</td>\n",
       "      <td>The balance between the potential benefits and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title  \\\n",
       "Date                                                            \n",
       "2010-12-15  Pulmonary responses to printer toner particles...   \n",
       "2010-12-14  Strategy for the modification of electrospun f...   \n",
       "2010-12-10  Management of nanomaterials safety in research...   \n",
       "2010-12-07  In vitro model on glass surfaces for complex i...   \n",
       "2010-12-01  The evolving nanotechnology environmental, hea...   \n",
       "...                                                       ...   \n",
       "2005-12-01  Translocation of inhaled TiO<inf>2</inf> nanop...   \n",
       "2005-10-01  Status of study on biological and toxicologica...   \n",
       "2005-04-01  The promise and threat of nanotechnology: Can ...   \n",
       "2005-03-01  Environmentally responsible development of nan...   \n",
       "2005-02-01  Societal implications of nanoscience and nanot...   \n",
       "\n",
       "                                                      Content  \n",
       "Date                                                           \n",
       "2010-12-15  The release of ultrafine particles from office...  \n",
       "2010-12-14  A method to functionalize surfaces of electros...  \n",
       "2010-12-10  Despite numerous discussions, workshops, revie...  \n",
       "2010-12-07  This report establishes an in vitro model on g...  \n",
       "2010-12-01                                                NaN  \n",
       "...                                                       ...  \n",
       "2005-12-01  Nanosized TiO2 is widely used for cleaning air...  \n",
       "2005-10-01  Because the physical and chemical properties o...  \n",
       "2005-04-01  The growing presence of the products of nanote...  \n",
       "2005-03-01                                                NaN  \n",
       "2005-02-01  The balance between the potential benefits and...  \n",
       "\n",
       "[197 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_scopus_dash().search_request_funt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
